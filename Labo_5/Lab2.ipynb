{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Neural networks\n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "> Add an extra layer to the network. This layer should have 20 nodes.\n",
    "\n",
    "> To do this re-use your forward and backpropagation function (e.g.: forward(forward(...)...)) (backward(backward(...)...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Benjamin Fraeyman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from NN_Helper import Gradient_Checker\n",
    "gradient_checker = Gradient_Checker(limit=1.0*np.exp(-8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create toy dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set containing samples with features\n",
    "X = np.array([  [0.,0.,1.,0.],\n",
    "                [0.,1.,1.,0.],\n",
    "                [1.,0.,1.,0.],\n",
    "                [1.,1.,1.,0.],\n",
    "                [0.,0.,1.,1.],\n",
    "                [0.,1.,1.,1.]])\n",
    "\n",
    "# Ground truth\n",
    "y = np.array([  [1.,0.,0.],\n",
    "                [1.,0.,0.],\n",
    "                [0.,1.,0.],\n",
    "                [0.,1.,0.],\n",
    "                [0.,0.,1.],\n",
    "                [0.,0.,1.]])\n",
    "\n",
    "n_samples = float(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weight matrices\n",
    "\n",
    "> Set the dimensions for the weight matrices.\n",
    "\n",
    "> Think about what the dimensions of the input data is, how many hidden nodes there have to be and how many classes there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "# 4nodes naar 20, van 20 naar 3\n",
    "w1 = 2*np.random.random((4,20)) - 1\n",
    "w2 = 2*np.random.random((20,3)) - 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activiation function and the derivative of this function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "        output = 1/(1+np.exp(-x))\n",
    "        return output\n",
    "    \n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_output_to_derivative(output):\n",
    "        return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward propagation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the forward propagation function you wrote in the previous exercise\n",
    "def forward(input_layer=None,weights=None):\n",
    "    p = np.dot(input_layer,weights)\n",
    "    a = sigmoid(p)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the backwardpropagation function you wrote in the previous exercise\n",
    "def backwards(input_layer=None,weights=None, a=None, dlda=None):\n",
    "    dadp = sigmoid_output_to_derivative(a)\n",
    "    dpdw = input_layer.T\n",
    "    dldw = np.dot(dpdw,dlda*dadp)\n",
    "    dpdx = weights.T\n",
    "    dldx = np.dot(dlda*dadp, dpdx)\n",
    "    return dldw,dldx\n",
    "\n",
    "#should return:\n",
    "#Gradient of the loss with respect to the weights\n",
    "#Gradient of the loss with respect to the input of the layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the loss function you wrote in the previous exercise\n",
    "def squared_loss(predicted=None,target=None):\n",
    "    loss = 0.5*np.sum((predicted-target)**2) \n",
    "    loss /= n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative of the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the function to calculate the derivative of the loss function\n",
    "def squared_loss_derrivative(predicted=None,target=None):\n",
    "        dlda = predicted-target\n",
    "        return dlda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function\n",
    "\n",
    "> In the main function the gradient check is also executed. \n",
    "> The difference between the analytical gradient and numerical gradient should be smaller than 1.0 e^-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good gradient, difference is: 7.141825896519404e-10\n",
      "Good gradient, difference is: 1.5302194098809935e-09\n",
      "Good gradient, difference is: 4.4324552502664743e-10\n",
      "Good gradient, difference is: 5.348716029286106e-10\n",
      "Good gradient, difference is: 1.1387767948100313e-09\n",
      "Good gradient, difference is: 9.38423632859595e-10\n"
     ]
    }
   ],
   "source": [
    "# A list to store the loss per epoch in. We can plot this later on to see if the network learns something\n",
    "loss_list=[]\n",
    "\n",
    "# How many times we will do the combination of forward and backward propagation\n",
    "n_epoch = 60000\n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "for iter in xrange(n_epoch):\n",
    "    \n",
    "    #Use the forwards and backwards function to create a TWO layer neural network\n",
    "    #Again make sure to calculate dldx, which is the gradient of the loss function with respect to the input of the network\n",
    "    #Calculate the loss and add it to the loss_list\n",
    "    a1 = forward(input_layer=X,weights=w1)\n",
    "    a2 = forward(input_layer=a1,weights=w2)\n",
    "    \n",
    "    loss_list.append(squared_loss(predicted=a2,target=y))\n",
    "    \n",
    "    dldw2, dldx2 = backwards(input_layer= a1,weights=w2, a=a2, dlda = squared_loss_derrivative(predicted=a2,target=y))\n",
    "    dldw2 /= n_samples\n",
    "    dldw, dldx = backwards(input_layer= X,weights=w1, a=a1, dlda = dldx2)\n",
    "    dldw /= n_samples\n",
    "    \n",
    "    # Gradient check.\n",
    "    if iter % 10000 == 0.:\n",
    "        f = lambda x: squared_loss(target=y,predicted=forward(input_layer=forward(input_layer=X,weights=w1),weights=w2))\n",
    "        gradient_checker.gradient_check(X,y,dldx,f)\n",
    "\n",
    "    #Do not forget to update the weights using the gradient descent update rule\n",
    "    w1 += -learning_rate*dldw\n",
    "    w2 += -learning_rate*dldw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "\n",
      "The output of the network\n",
      "\n",
      "[[0.92031222 0.06250365 0.06229378]\n",
      " [0.93141899 0.05430874 0.05183625]\n",
      " [0.04954046 0.9431526  0.01581519]\n",
      " [0.05987846 0.93720495 0.01258012]\n",
      " [0.05194591 0.00990782 0.94382371]\n",
      " [0.05385695 0.00877013 0.94370757]]\n",
      "\n",
      "The ground truth:\n",
      "\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "\n",
      "\n",
      "Apply argmax on the output to get the index per row where the value is maximum\n",
      "\n",
      "Prediction network\n",
      "\n",
      "[0 0 1 1 2 2]\n",
      "\n",
      "Ground truth\n",
      "\n",
      "[0 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print \"Output After Training:\"\n",
    "print\n",
    "print \"The output of the network\"\n",
    "print\n",
    "print a2\n",
    "print\n",
    "print \"The ground truth:\"\n",
    "print\n",
    "print y\n",
    "print\n",
    "print\n",
    "print \"Apply argmax on the output to get the index per row where the value is maximum\"\n",
    "print\n",
    "print \"Prediction network\"\n",
    "print\n",
    "print np.argmax(a2,axis=1)\n",
    "print\n",
    "print \"Ground truth\"\n",
    "print\n",
    "print np.argmax(y,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "Lab2.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
