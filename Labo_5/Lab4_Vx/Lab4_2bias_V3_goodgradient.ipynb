{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Neural networks\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "> In this final exercise you will have to create a neural network to classify hand written numbers. Such a neural network is for example used in the post sorting process.\n",
    "\n",
    "> The dataset consists of images of hand written numbers ranging from 0 till 9.\n",
    "\n",
    "> Your goal is to train a neural network on the training set (*X_train*) and predict on the test_set (*X_test*)\n",
    "\n",
    "> Try to get an accuracy as high as possible. Decide yourself what to modify. You can modify for example: the learning_rate, amount of layers, neurons per layer, preprocessing methods, gradient descent to stochastic gradient descent/ batch gradient descent...\n",
    "\n",
    "> Feel free to change other aspects too if you want (e.g. activation function, but then you have to change to backprop algorithm).\n",
    "\n",
    "#### A few hints:\n",
    "\n",
    "> Calculate the accuracy on both the training set (X_train) and testing set (X_test) to see if there is a large difference\n",
    "\n",
    "> You can also do this every 5,10,... epochs (monitor the accuracy)\n",
    "\n",
    "> Calculate the loss on the training set, but also the test set (monitor the loss)\n",
    "\n",
    "> Plot these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Benjamin Fraeyman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from NN_Helper import Gradient_Checker\n",
    "gradient_checker = Gradient_Checker(limit=1.0*np.exp(-8))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create toy dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1797L, 64L)\n",
      "y.shape: (1797L, 10L)\n",
      "X_train.shape: (1700L, 64L)\n",
      "X_test.shape: (97L, 64L)\n",
      "y_train.shape: (1700L, 10L)\n",
      "y_test.shape: (97L, 10L)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set containing samples with features\n",
    "data = load_digits(10)\n",
    "X = data['data']\n",
    "print \"X.shape:\", X.shape\n",
    "y = data['target']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(np.reshape(y,(len(y),1))).toarray()\n",
    "print \"y.shape:\", y.shape\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train = X[:1700]\n",
    "print \"X_train.shape:\", X_train.shape\n",
    "X_test = X[1700:]\n",
    "print \"X_test.shape:\", X_test.shape\n",
    "y_train = y[:1700]\n",
    "print \"y_train.shape:\", y_train.shape\n",
    "y_test = y[1700:]\n",
    "print \"y_test.shape:\", y_test.shape\n",
    "\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(np.reshape(X[i*100],(8,8)),cmap=plt.cm.gray,interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-use the code of exercise 3 (backwards, forwards, loss,...)** (you may use more cells if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- reused code here --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1700.0\n",
      "n_neurons: 10\n",
      "w1.shape: (64L, 10L)\n",
      "w2.shape: (10L, 10L)\n",
      "b1.shape: (1L, 10L)\n",
      "b2.shape: (1L, 10L)\n"
     ]
    }
   ],
   "source": [
    "n_samples = float(len(X_train))\n",
    "print \"n_samples:\", n_samples\n",
    "n_neurons = 10\n",
    "print \"n_neurons:\", n_neurons\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "w1 = 2*np.random.random((X_train.shape[1],n_neurons)) - 1\n",
    "print \"w1.shape:\", w1.shape\n",
    "w2 = 2*np.random.random((n_neurons,y_train.shape[1])) - 1\n",
    "print \"w2.shape:\", w2.shape\n",
    "\n",
    "# initialize the bias for every layer\n",
    "b1 = np.zeros((1,n_neurons))\n",
    "print \"b1.shape:\", b1.shape\n",
    "b2 = np.zeros((1,y_train.shape[1]))\n",
    "print \"b2.shape:\", b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activiation function and the derivative of this function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "        output = 1/(1+np.exp(-x))\n",
    "        return output\n",
    "    \n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_output_to_derivative(output):\n",
    "        return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the forward propagation function you wrote in the previous exercise\n",
    "#update it to use a bias\n",
    "def forward(input_layer=None,weights=None,bias=None):\n",
    "    p = np.dot(input_layer,weights) +bias\n",
    "    a = sigmoid(p)\n",
    "    return a\n",
    "\n",
    "# https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "def backwards(input_layer=None,weights=None, a=None, dlda=None):\n",
    "    dadp = sigmoid_output_to_derivative(a)\n",
    "    \n",
    "    dpdw = input_layer.T\n",
    "    dldw = np.dot(dpdw,dlda*dadp)\n",
    "    \n",
    "    # (a+w) afgeleid naar w => 1\n",
    "    dldp = dlda*dadp\n",
    "    ones = np.ones((1, int(n_samples)))\n",
    "    dldb = np.dot(ones,dldp)\n",
    "    \n",
    "    dpdx = weights.T\n",
    "    dldx = np.dot(dlda*dadp, dpdx)\n",
    "    \n",
    "    dldw /= n_samples\n",
    "    dldb /= n_samples\n",
    "    return dldw,dldb,dldx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(predicted=None,target=None):\n",
    "    loss = 0.5*np.sum((predicted-target)**2)\n",
    "    loss /= n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative of the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss_derrivative(predicted=None,target=None):\n",
    "        dlda = predicted-target\n",
    "        return dlda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- end of reused code --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 4999\n",
      "Good gradient, difference is: 0.00029180868811055975\n"
     ]
    }
   ],
   "source": [
    "#<Fill-in>-----------\n",
    "# A list to store the loss per epoch in. We can plot this later on to see if the network learns something\n",
    "loss_list=[]\n",
    "# How many times we will do the combination of forward and backward propagation\n",
    "n_epoch = 5000\n",
    "#learning rate\n",
    "learning_rate = 10\n",
    "# --------------------\n",
    "\n",
    "for iter in xrange(n_epoch):\n",
    "    #print \"iter:\", iter\n",
    "    a1 = forward(input_layer=X_train,weights=w1,bias=b1)\n",
    "    a2 = forward(input_layer=a1,weights=w2,bias=b2)\n",
    "    loss = squared_loss(predicted=a2,target=y_train)\n",
    "    loss_list.append(loss)\n",
    "    dldw2, dldb2, dldx2 = backwards(input_layer= a1,weights=w2, a=a2, dlda = squared_loss_derrivative(predicted=a2,target=y_train))\n",
    "    dldw, dldb, dldx = backwards(input_layer= X_train,weights=w1, a=a1, dlda = dldx2/n_samples)\n",
    "#     if iter != 0.:\n",
    "#         if iter % 10000 == 0.:\n",
    "#             print \"iter:\", iter\n",
    "#             f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "#             gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    if iter == 4999:\n",
    "        print \"iter:\", iter\n",
    "        f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "        gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    w1 += -learning_rate*dldw\n",
    "    w2 += -learning_rate*dldw2\n",
    "    b1 += -learning_rate*dldb\n",
    "    b2 += -learning_rate*dldb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7441176470588236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculate the accuracy for X_train using the \"accuracy_score\" function from scikit-learn which is already imported \n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "accuracy_score(np.argmax(y_train,axis=1), np.argmax(a2,axis=1))\n",
    "# #Calculate the accuracy for X_test using \"the accuracy_score\"\n",
    "# <Fill-in>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "\n",
      "The output of the network\n",
      "\n",
      "[[2.90467647e-06 1.35218313e-01 4.95686732e-01 ... 4.74669961e-06\n",
      "  3.59974280e-02 3.60354900e-03]\n",
      " [2.56258762e-05 3.45165549e-02 7.18024062e-01 ... 1.65268130e-06\n",
      "  1.34240658e-01 4.44485473e-02]\n",
      " [2.53466444e-07 8.33012144e-02 5.41163723e-01 ... 2.08225399e-05\n",
      "  3.22165686e-02 3.96464930e-03]\n",
      " ...\n",
      " [1.52466070e-08 2.69853189e-01 2.40580769e-01 ... 3.61108564e-04\n",
      "  4.85040859e-02 6.18673122e-03]\n",
      " [1.33445727e-05 4.78520749e-03 5.73325339e-04 ... 5.10240540e-03\n",
      "  9.92894429e-02 9.31203646e-01]\n",
      " [4.29386864e-08 3.03372314e-03 8.29868878e-03 ... 3.34543987e-07\n",
      "  4.69773860e-04 5.50738231e-05]]\n",
      "\n",
      "The ground truth:\n",
      "\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Apply argmax on the output to get the index per row where the value is maximum\n",
      "\n",
      "Prediction network\n",
      "\n",
      "[2 2 2 ... 1 9 5]\n",
      "\n",
      "Ground truth\n",
      "\n",
      "[2 8 2 ... 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "print \"Output After Training:\"\n",
    "print\n",
    "print \"The output of the network\"\n",
    "print\n",
    "print a2\n",
    "print\n",
    "print \"The ground truth:\"\n",
    "print\n",
    "print y_train\n",
    "print\n",
    "print\n",
    "print \"Apply argmax on the output to get the index per row where the value is maximum\"\n",
    "print\n",
    "print \"Prediction network\"\n",
    "print\n",
    "print np.argmax(a2,axis=1)\n",
    "print\n",
    "print \"Ground truth\"\n",
    "print\n",
    "print np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question: What is the accuracy you achieved on X_test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Fill - in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What modifications did you do to receive this score?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "Lab4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
