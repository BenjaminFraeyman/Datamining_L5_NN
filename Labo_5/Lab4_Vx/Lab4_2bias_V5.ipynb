{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Neural networks\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "> In this final exercise you will have to create a neural network to classify hand written numbers. Such a neural network is for example used in the post sorting process.\n",
    "\n",
    "> The dataset consists of images of hand written numbers ranging from 0 till 9.\n",
    "\n",
    "> Your goal is to train a neural network on the training set (*X_train*) and predict on the test_set (*X_test*)\n",
    "\n",
    "> Try to get an accuracy as high as possible. Decide yourself what to modify. You can modify for example: the learning_rate, amount of layers, neurons per layer, preprocessing methods, gradient descent to stochastic gradient descent/ batch gradient descent...\n",
    "\n",
    "> Feel free to change other aspects too if you want (e.g. activation function, but then you have to change to backprop algorithm).\n",
    "\n",
    "#### A few hints:\n",
    "\n",
    "> Calculate the accuracy on both the training set (X_train) and testing set (X_test) to see if there is a large difference\n",
    "\n",
    "> You can also do this every 5,10,... epochs (monitor the accuracy)\n",
    "\n",
    "> Calculate the loss on the training set, but also the test set (monitor the loss)\n",
    "\n",
    "> Plot these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Benjamin Fraeyman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from NN_Helper import Gradient_Checker\n",
    "gradient_checker = Gradient_Checker(limit=1.0*np.exp(-8))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create toy dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1797L, 64L)\n",
      "y.shape: (1797L, 10L)\n",
      "X_train.shape: (1700L, 64L)\n",
      "X_test.shape: (97L, 64L)\n",
      "y_train.shape: (1700L, 10L)\n",
      "y_test.shape: (97L, 10L)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set containing samples with features\n",
    "data = load_digits(10)\n",
    "X = data['data']\n",
    "print \"X.shape:\", X.shape\n",
    "y = data['target']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(np.reshape(y,(len(y),1))).toarray()\n",
    "print \"y.shape:\", y.shape\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train = X[:1700]\n",
    "print \"X_train.shape:\", X_train.shape\n",
    "X_test = X[1700:]\n",
    "print \"X_test.shape:\", X_test.shape\n",
    "y_train = y[:1700]\n",
    "print \"y_train.shape:\", y_train.shape\n",
    "y_test = y[1700:]\n",
    "print \"y_test.shape:\", y_test.shape\n",
    "\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(np.reshape(X[i*100],(8,8)),cmap=plt.cm.gray,interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-use the code of exercise 3 (backwards, forwards, loss,...)** (you may use more cells if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- reused code here --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1700.0\n",
      "n_neurons: 10\n",
      "w1.shape: (64L, 10L)\n",
      "w2.shape: (10L, 10L)\n",
      "b1.shape: (1L, 10L)\n",
      "b2.shape: (1L, 10L)\n"
     ]
    }
   ],
   "source": [
    "n_samples = float(len(X_train))\n",
    "print \"n_samples:\", n_samples\n",
    "n_neurons = 10\n",
    "print \"n_neurons:\", n_neurons\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "w1 = 2*np.random.random((X_train.shape[1],n_neurons)) - 1\n",
    "print \"w1.shape:\", w1.shape\n",
    "w2 = 2*np.random.random((n_neurons,y_train.shape[1])) - 1\n",
    "print \"w2.shape:\", w2.shape\n",
    "\n",
    "# initialize the bias for every layer\n",
    "b1 = np.zeros((1,n_neurons))\n",
    "print \"b1.shape:\", b1.shape\n",
    "b2 = np.zeros((1,y_train.shape[1]))\n",
    "print \"b2.shape:\", b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activiation function and the derivative of this function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "        output = 1/(1+np.exp(-x))\n",
    "        return output\n",
    "    \n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_output_to_derivative(output):\n",
    "        return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the forward propagation function you wrote in the previous exercise\n",
    "#update it to use a bias\n",
    "def forward(input_layer=None,weights=None,bias=None):\n",
    "    p = np.dot(input_layer,weights) +bias\n",
    "    a = sigmoid(p)\n",
    "    return a\n",
    "\n",
    "# https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "def backwards(input_layer=None,weights=None, a=None, dlda=None):\n",
    "    dadp = sigmoid_output_to_derivative(a)\n",
    "    \n",
    "    dpdw = input_layer.T\n",
    "    dldw = np.dot(dpdw,dlda*dadp)\n",
    "    \n",
    "    # (a+w) afgeleid naar w => 1\n",
    "    dldp = dlda*dadp\n",
    "    ones = np.ones((1, int(n_samples)))\n",
    "    dldb = np.dot(ones,dldp)\n",
    "    \n",
    "    dpdx = weights.T\n",
    "    dldx = np.dot(dlda*dadp, dpdx)\n",
    "    \n",
    "    dldw /= n_samples\n",
    "    dldb /= n_samples\n",
    "    return dldw,dldb,dldx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(predicted=None,target=None):\n",
    "    loss = 0.5*np.sum((predicted-target)**2)\n",
    "    loss /= n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative of the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss_derrivative(predicted=None,target=None):\n",
    "        dlda = predicted-target\n",
    "        return dlda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- end of reused code --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 4999\n",
      "Good gradient, difference is: 0.00031822497974791754\n"
     ]
    }
   ],
   "source": [
    "#<Fill-in>-----------\n",
    "# A list to store the loss per epoch in. We can plot this later on to see if the network learns something\n",
    "loss_list=[]\n",
    "# How many times we will do the combination of forward and backward propagation\n",
    "n_epoch = 5000\n",
    "#learning rate\n",
    "learning_rate = 11\n",
    "# --------------------\n",
    "\n",
    "for iter in xrange(n_epoch):\n",
    "    a1 = forward(input_layer=X_train,weights=w1,bias=b1)\n",
    "    a2 = forward(input_layer=a1,weights=w2,bias=b2)\n",
    "    a3 = forward(input_layer=X_test,weights=w1,bias=b1)\n",
    "    a4 = forward(input_layer=a3,weights=w2,bias=b2)\n",
    "    loss = squared_loss(predicted=a2,target=y_train)\n",
    "    loss_list.append(loss)\n",
    "    dldw2, dldb2, dldx2 = backwards(input_layer= a1,weights=w2, a=a2, dlda = squared_loss_derrivative(predicted=a2,target=y_train))\n",
    "    dldw, dldb, dldx = backwards(input_layer= X_train,weights=w1, a=a1, dlda = dldx2/n_samples)\n",
    "#     if iter != 0.:\n",
    "#         if iter % 4999 == 0.:\n",
    "#             print \"iter:\", iter\n",
    "#             f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "#             gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    if iter == 4999:\n",
    "            print \"iter:\", iter\n",
    "            f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "            gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    w1 += -learning_rate*dldw\n",
    "    w2 += -learning_rate*dldw2\n",
    "    b1 += -learning_rate*dldb\n",
    "    b2 += -learning_rate*dldb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7570588235294118\n",
      "0.7525773195876289\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy for X_train using the \"accuracy_score\" function from scikit-learn which is already imported \n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "print accuracy_score(np.argmax(y_train,axis=1), np.argmax(a2,axis=1))\n",
    "# #Calculate the accuracy for X_test using \"the accuracy_score\"\n",
    "print accuracy_score(np.argmax(y_test,axis=1), np.argmax(a4,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "\n",
      "The output of the network\n",
      "\n",
      "[[1.00639380e-05 1.20796906e-01 6.12538910e-01 ... 1.05323776e-06\n",
      "  4.93768354e-02 7.09991893e-03]\n",
      " [3.15201504e-05 1.16264219e-02 6.57897150e-01 ... 2.13300479e-06\n",
      "  1.69968060e-01 4.54666001e-02]\n",
      " [1.37281693e-07 8.35000573e-02 5.48023845e-01 ... 2.00563076e-05\n",
      "  2.44263745e-02 2.16099272e-03]\n",
      " ...\n",
      " [2.74379940e-09 4.17281836e-01 1.55264735e-01 ... 1.25731949e-03\n",
      "  4.49728519e-02 3.99698341e-03]\n",
      " [1.11838487e-05 4.70046715e-03 5.32460311e-04 ... 4.09095009e-03\n",
      "  1.10153308e-01 9.43377931e-01]\n",
      " [2.98594808e-08 4.14380387e-03 6.66930304e-03 ... 2.82756329e-07\n",
      "  3.48688043e-04 2.55159893e-05]]\n",
      "\n",
      "The ground truth:\n",
      "\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Apply argmax on the output to get the index per row where the value is maximum\n",
      "\n",
      "Prediction network\n",
      "\n",
      "[2 2 2 ... 1 9 5]\n",
      "\n",
      "Ground truth\n",
      "\n",
      "[2 8 2 ... 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "print \"Output After Training:\"\n",
    "print\n",
    "print \"The output of the network\"\n",
    "print\n",
    "print a2\n",
    "print\n",
    "print \"The ground truth:\"\n",
    "print\n",
    "print y_train\n",
    "print\n",
    "print\n",
    "print \"Apply argmax on the output to get the index per row where the value is maximum\"\n",
    "print\n",
    "print \"Prediction network\"\n",
    "print\n",
    "print np.argmax(a2,axis=1)\n",
    "print\n",
    "print \"Ground truth\"\n",
    "print\n",
    "print np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAF8VJREFUeJzt3X+Q3HV9x/Hn+/bX/cxdyF0gzSUkgWBlKDbMCTgoYos2MA7UGUYTtf4CM6PFtqPTFsYOtugf1c60VgeLGUuZtgri+Ctl4kRHoagUzCESEzBwhF9HIHcJ5H7v3e3l3T/2u5fNZve+m9xe9r7fez1mdvb745Pdz+dYXp/vfj772TV3R0RE4qWh3hUQEZHaU7iLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgMKdxFRGJI4S4iEkMKdxGRGErW64k7Ozt93bp19Xp6EZFIeuyxxw67e1dYubqF+7p16+jt7a3X04uIRJKZvVBNOQ3LiIjEkMJdRCSGFO4iIjGkcBcRiSGFu4hIDCncRURiSOEuIhJDkQv3pw+N8M8/3s/h0cl6V0VEZNGKXLg/c2iUr/ysj9fGpupdFRGRRSty4S4iIuEU7iIiMaRwFxGJociGu3u9ayAisnhFLtzN6l0DEZHFL3LhLiIi4RTuIiIxpHAXEYmhyIa7oxlVEZFKIhfumk8VEQkXuXAXEZFwCncRkRhSuIuIxFBkw10rVEVEKgsNdzO7y8wGzGxvSLk3m9mMmd1Qu+qVe56FfHQRkXio5sr9bmDzXAXMLAF8EdhVgzqJiMg8hYa7uz8EvBZS7FPAd4GBWlRKRETmZ95j7ma2GngPcGcVZbeZWa+Z9Q4ODs73qUVEpIJaTKh+Gfhbd58JK+ju2929x917urq65vWkmlAVEaksWYPH6AHutfxMZydwrZnl3P0HNXjsMjSjKiISZt7h7u7rC9tmdjdw/8IFu4iIVCM03M3sHuAqoNPM+oHPASkAdw8dZxcRkTMvNNzdfWu1D+buH5lXbUREpCaiu0JVX/krIlJR5MJdK1RFRMJFLtxFRCScwl1EJIYU7iIiMRTZcNcKVRGRyiIX7ppPFREJF7lwFxGRcAp3EZEYUriLiMSQwl1EJIYiF+6mJaoiIqEiF+4iIhJO4S4iEkMKdxGRGIpsuGuFqohIZZELd02nioiEi1y4i4hIOIW7iEgMKdxFRGIoNNzN7C4zGzCzvRXOf8DM9gS3h83sTbWv5sn0G6oiIpVVc+V+N7B5jvPPAW9394uBzwPba1CvirRAVUQkXDKsgLs/ZGbr5jj/cNHuI0D3/KslIiLzUesx9xuBH9X4MUVE5BSFXrlXy8zeQT7c3zpHmW3ANoC1a9fW6qlFRKRETa7czexi4BvA9e5+pFI5d9/u7j3u3tPV1TWv59QKVRGRyuYd7ma2Fvge8Gfu/vT8qxT2fAv9DCIi0Rc6LGNm9wBXAZ1m1g98DkgBuPudwG3ACuBrwXet59y9Z6EqLCIi4ar5tMzWkPM3ATfVrEYiIjJvWqEqIhJDkQ13zaeKiFQWuXA3femviEioyIW7iIiEU7iLiMRQZMPdtYpJRKSiyIa7iIhUFr1w13yqiEio6IW7iIiEUriLiMRQZMNd06kiIpVFLtw15C4iEi5y4S4iIuEU7iIiMaRwFxGJociGuxaoiohUFrlwN/3OnohIqMiFu4iIhFO4i4jEkMJdRCSGQsPdzO4yswEz21vhvJnZV8ysz8z2mNklta9mOZpRFRGppJor97uBzXOcvwbYGNy2Af82/2pVpulUEZFwoeHu7g8Br81R5HrgPz3vEaDDzFbVqoIiInLqajHmvhp4qWi/PzgmIiJ1UotwLzdSUnZA3My2mVmvmfUODg7W4KlFRKScWoR7P7CmaL8bOFiuoLtvd/ced+/p6uqa15NqhaqISGW1CPcdwIeCT81cDgy5+ys1eNyytEBVRCRcMqyAmd0DXAV0mlk/8DkgBeDudwI7gWuBPmAc+OhCVVZERKoTGu7uvjXkvAN/XrMaiYjIvGmFqohIDEU23DWfKiJSWeTC3bRGVUQkVOTCXUREwincRURiSOEuIhJDkQ13rVAVEakscuGuFaoiIuEiF+4iIhJO4S4iEkMKdxGRGIpsuLtmVEVEKopcuGs+VUQkXOTCXUREwincRURiSOEuIhJDkQ13TaeKiFQWvXDXjKqISKjohbuIiIRSuIuIxJDCXUQkhqoKdzPbbGb7zazPzG4pc36tmT1gZo+b2R4zu7b2VT2RFqiKiFQWGu5mlgDuAK4BLgS2mtmFJcX+DrjP3TcBW4Cv1bqis/XRjKqISKhqrtwvBfrc/YC7TwH3AteXlHFgWbDdDhysXRVFRORUJasosxp4qWi/H7ispMzfAz82s08BLcDVNamdiIiclmqu3MuNg5SOeG8F7nb3buBa4L/M7KTHNrNtZtZrZr2Dg4OnXlsREalKNeHeD6wp2u/m5GGXG4H7ANz9/4BGoLP0gdx9u7v3uHtPV1fX6dW48FhaoyoiUlE14b4b2Ghm680sTX7CdEdJmReBPwYwszeSD/cFuTTXb6iKiIQLDXd3zwE3A7uAp8h/Kmafmd1uZtcFxT4DfNzMngDuAT7i+jUNEZG6qWZCFXffCewsOXZb0faTwBW1rZqIiJwurVAVEYmh6Ia7Bn1ERCqKXLhrPlVEJFzkwl1ERMIp3EVEYkjhLiISQ5ENd82niohUFrlwNy1RFREJFblwFxGRcAp3EZEYUriLiMRQZMNdX0smIlJZ5MJd86kiIuEiF+4iIhJO4S4iEkMKdxGRGIpsuOs3VEVEKotcuGs+VUQkXOTCXUREwincRURiqKpwN7PNZrbfzPrM7JYKZd5rZk+a2T4z+1ZtqykiIqciGVbAzBLAHcA7gX5gt5ntcPcni8psBG4FrnD3181s5UJVuEArVEVEKqvmyv1SoM/dD7j7FHAvcH1JmY8Dd7j76wDuPlDbah6nFaoiIuGqCffVwEtF+/3BsWIXABeY2S/N7BEz21yrCoqIyKkLHZah/KcPSwdFksBG4CqgG/i5mV3k7kdPeCCzbcA2gLVr155yZUVEpDrVXLn3A2uK9ruBg2XK/NDdp939OWA/+bA/gbtvd/ced+/p6uo63TqLiEiIasJ9N7DRzNabWRrYAuwoKfMD4B0AZtZJfpjmQC0rWkrzqSIilYWGu7vngJuBXcBTwH3uvs/Mbjez64Jiu4AjZvYk8ADw1+5+ZGGqrBlVEZEw1Yy54+47gZ0lx24r2nbg08FNRETqTCtURURiSOEuIhJDkQ131xJVEZGKIhfuWqEqIhIucuEuIiLhFO4iIjGkcBcRiaHIhrumU0VEKotcuGs+VUQkXOTCXUREwincRURiSOEuIhJDkQv35nT+u86GJ6brXBMRkcUrcuG+rrOZRIPx9KGReldFRGTRily4Z5IJzutqYf+rCncRkUoiF+4AbzhnGb9TuIuIVBTJcP/9c9rof32CkazG3UVEyolkuL/h7DYAjbuLiFQQzXA/Jx/uGpoRESkvkuHevbyJ1kxSk6oiIhVEMtzNjA1dLRwYHKt3VUREFqWqwt3MNpvZfjPrM7Nb5ih3g5m5mfXUrorlbehs4cDg6EI/jYhIJIWGu5klgDuAa4ALga1mdmGZcm3AXwCP1rqS5WzoauXgUJbxqdyZeDoRkUip5sr9UqDP3Q+4+xRwL3B9mXKfB74EZGtYv4rO62oF4LnDGpoRESlVTbivBl4q2u8Pjs0ys03AGne/f64HMrNtZtZrZr2Dg4OnXNliG7paADTuLiJSRjXhXu73MWZ/CMnMGoB/AT4T9kDuvt3de9y9p6urq/palrG+swUzhbuISDnVhHs/sKZovxs4WLTfBlwEPGhmzwOXAzsWelK1MZXg99qbOHBYk6oiIqWqCffdwEYzW29maWALsKNw0t2H3L3T3de5+zrgEeA6d+9dkBoX0cchRUTKCw13d88BNwO7gKeA+9x9n5ndbmbXLXQF53JeVyvPDo4yc0w/ly0iUixZTSF33wnsLDl2W4WyV82/WtXZtLaDux9+nn0Hh7i4u+NMPa2IyKIXyRWqBW85bwUAP3/mcJ1rIiKyuEQ63Fe2NbJpbQc/ePxl3DU0IyJSEOlwB3hvzxqeGRjll31H6l0VEZFFI/Lh/p5Nq1nd0cTn73+SiamZeldHRGRRiHy4N6YSfOE9F/H0wAif/OZjjE3qu2ZERCIf7gDveMNKvvCnF/G/Tw/y7q/+ggf3D2gMXkSWtFiEO8AHLjuX/77xMtydj/zHbt791V/w7d0vMjSu31kVkaXH6nWF29PT4729tV/EOpmb4fu/fplv/OI5+gZGSSWMK87v5MqNXbxtYyfnr2zFrNzX5YiILH5m9pi7h369S1WLmKIkk0yw5dK1vO/Na9j78jD/s+cgu/a9yoP7899CubItw6a1HVzc3cGbujv4g+522ptSda61iEhtxe7KvZKXXhvnl32HefjZI+zpP8rzR8Znz529LMP5K1s5v6uV81e2cl5XK2vOamZVeyPJRGxGrkQkBqq9cl8y4V7q6PgUe/qH2HtwiL6BUZ4dGKVvYJSxoo9TJhqMc5Y1suasJrqXN9O9vInVHU2c097I2csaWdmWob0ppWEeETljluywTLU6mtNceUEXV15w/Hvl3Z1Xh7McGByj//Vx+l+fCG75q/5Xh7OU9oXpZANnL8twdlsjK5dlWNl2PPhXtKbpbM3fn9WSJpNMnOFWishStWTDvRwzY1V7E6vam8qen8od45WhCQ4NT3JoOMvAyCQDw1kODWc5NDzJ714d4aGnDzNa4bP2bZkkK1rTrGjNsKIlnd9uyZQ91tGcIqUhIRE5TQr3U5BONnDuihbOXdEyZ7mxyRwDI5O8NjbJ4dEpjoxOHd8ey2+/+No4v37xKK+PT1X8yuKWdIKO5jTtTSnam1J0NOfv25tTdDSlTzwW3JY1pmhtTJJo0FCRyFKmcF8ALZkk6zNJ1nfO3QkAHDvmDE1Mc2RskiNB+B8ZneTo+DRHJ6YZmpjm6Pg0QxNTPDs4Ont8KndszsdtTidoa0zSmknS1piirTGZv2Xy4V84V+gM8udTQfn8ueZ0QvMJIhGlcK+zhgZjeUua5S1pzl9Z/b/LTs8EQT/FUKEjGJ9mZDLHSHaa0WyOkWyO0ckcw9lpRrI5XhnKMhJsj1fxPTxm0JpO0pJJ0tqYv2/LJGnJJGjNpGjNJEqO5zuF1qBzaC3ab0qpoxA5kxTuEdWYSnBOe4Jz2htP69/nZo4xNjnDcHaa0clCR5AP/pFsjrHJfMcwOpljNJtjbOr48YGRLGOTM4xkpxmbmqnql7AajOPhH3QEbY1JWtIndgaFjuSEzmK2c0nQlknRmGpQRyESQuG+RCUTDbQ3N9DePL8FXO5OdvoYI5PTjE3OMJo93imMTeYYCe5Ljxe2Xx3KHu9EJnMnfRqpnAajJPRPfqdQTSfS1pgkk1RHIfGkcJd5MTOa0gma0glom99juTsT0yd2EMXvHPLHZxgNOpLidxjDwbDTaOHYVHUdRaLBZucZljWmWNZUuE/N7rfPbqdY1pjM3wfbLekkDZq8lkVI4S6LhpnRnE7SnE5yCtMPZR07FnQUxR1E8TuJouOFYanhiWmGs9O8cGSc4ew0wxPTJyxqK6fBoK24U6imgyg636JJa1kgVYW7mW0G/hVIAN9w938sOf9p4CYgBwwCH3P3F2pcV5GqNTQYLcHwy9nzeJzczLF88GenGZ7IzYZ+6f7QxDTDQQfx3OGx2XNhE9cNxgmdQPkOIv9uob0pdVJZfaJJKgkNdzNLAHcA7wT6gd1mtsPdnywq9jjQ4+7jZvYJ4EvA+xaiwiJnUjLRMPtpptMxXegcynQIlTqIZwdHZ89NTM/dOSQa7PhQ0VwdRLBd2kHoU0zxVc2V+6VAn7sfADCze4Hrgdlwd/cHiso/AnywlpUUiapUooGzWvJfP3E6pnLHGMkef1cQ1kEMZ3McGh6dPZednns9RLLBZt8dFNZDlK6NKExStzWmaCusgyhaF9Ga0aK5xaiacF8NvFS03w9cNkf5G4EfzadSIpKXTjbkv5qiNXNa/34yN1P0ziG8gxjN5nhhdHx2fUS1n2BqSSdoa0zRkknkh8PSydnt5nSS1kyC5uBYfl4lQVMqQWNwP7ufyk/ON6cTNCYTmqyeh2rCvdxft+x/bjP7INADvL3C+W3ANoC1a9dWWUUROV2ZZIJMa4LO0+wc3J3xqZmT1kGMBovlRoompAvrHsYmc4xPznDwaJaxqRxjk/ljYUNM5evfkA/7oo6gKegAyt4Xtov2G4N/31TUgTQHZeLcgVQT7v3AmqL9buBgaSEzuxr4LPB2d58s90Duvh3YDvmv/D3l2orIGWV2fGIaTm/BXMHMMWd8Kr86Ojs9w/jUDBPTM2SD+9n96RkmpmZmy00U9ovKjk7mGByZnD1X+HfTM6ceK5lkQ9l3Eo1FncUJ+2U6kIqdTR07kGrCfTew0czWAy8DW4D3Fxcws03A14HN7j5Q81qKSOQlGiwYy1+4Xz6bnjlWvsOo0IFMzHFfyw6kMdVwwjuJ91+6lpvetmEB/gLHhYa7u+fM7GZgF/mPQt7l7vvM7Hag1913AP8EtALfCWbeX3T36xaw3iIiJ0klGkglGlh2BjuQQqdx0v4cHcfpDpOdiqo+5+7uO4GdJcduK9q+usb1EhFZlM5EB1IL+jUIEZEYUriLiMSQwl1EJIYU7iIiMaRwFxGJIYW7iEgMKdxFRGJI4S4iEkPm1Xzl20I8sdkgcLo/6NEJHK5hdaJAbV4a1OalYT5tPtfdu8IK1S3c58PMet29p971OJPU5qVBbV4azkSbNSwjIhJDCncRkRiKarhvr3cF6kBtXhrU5qVhwdscyTF3ERGZW1Sv3EVEZA6RC3cz22xm+82sz8xuqXd95sPM7jKzATPbW3TsLDP7iZk9E9wvD46bmX0laPceM7uk6N98OCj/jJl9uB5tqYaZrTGzB8zsKTPbZ2Z/GRyPc5sbzexXZvZE0OZ/CI6vN7NHg/p/28zSwfFMsN8XnF9X9Fi3Bsf3m9mf1KdF1TOzhJk9bmb3B/uxbrOZPW9mvzWz35hZb3Csfq9td4/MjfwvQT0LbADSwBPAhfWu1zzacyVwCbC36NiXgFuC7VuALwbb1wI/Iv+D5ZcDjwbHzwIOBPfLg+3l9W5bhfauAi4JttuAp4ELY95mA1qD7RTwaNCW+4AtwfE7gU8E258E7gy2twDfDrYvDF7vGWB98P9Bot7tC2n7p4FvAfcH+7FuM/A80FlyrG6v7br/QU7xj/cWYFfR/q3ArfWu1zzbtK4k3PcDq4LtVcD+YPvrwNbScsBW4OtFx08ot5hvwA+Bdy6VNgPNwK+By8gvYEkGx2df1+R/zvItwXYyKGelr/XicovxBnQDPwX+CLg/aEPc21wu3Ov22o7asMxq4KWi/f7gWJyc7e6vAAT3K4Pjldoeyb9J8NZ7E/kr2Vi3ORie+A0wAPyE/BXoUXfPBUWK6z/btuD8ELCCiLUZ+DLwN8CxYH8F8W+zAz82s8fMbFtwrG6v7ap+Q3URsTLHlsrHfSq1PXJ/EzNrBb4L/JW7Dwc/ql62aJljkWuzu88Af2hmHcD3gTeWKxbcR77NZvZuYMDdHzOzqwqHyxSNTZsDV7j7QTNbCfzEzH43R9kFb3PUrtz7gTVF+93AwTrVZaEcMrNVAMH9QHC8Utsj9TcxsxT5YP+mu38vOBzrNhe4+1HgQfJjrB1mVri4Kq7/bNuC8+3Aa0SrzVcA15nZ88C95Idmvky824y7HwzuB8h34pdSx9d21MJ9N7AxmHVPk5982VHnOtXaDqAwQ/5h8uPSheMfCmbZLweGgrd5u4B3mdnyYCb+XcGxRcfyl+j/Djzl7v9cdCrObe4KrtgxsybgauAp4AHghqBYaZsLf4sbgJ95fvB1B7Al+GTJemAj8Ksz04pT4+63unu3u68j///oz9z9A8S4zWbWYmZthW3yr8m91PO1Xe9JiNOYtLiW/KcsngU+W+/6zLMt9wCvANPke+wbyY81/hR4Jrg/KyhrwB1Bu38L9BQ9zseAvuD20Xq3a472vpX8W8w9wG+C27Uxb/PFwONBm/cCtwXHN5APqj7gO0AmON4Y7PcF5zcUPdZng7/FfuCaeretyvZfxfFPy8S2zUHbnghu+wrZVM/XtlaoiojEUNSGZUREpAoKdxGRGFK4i4jEkMJdRCSGFO4iIjGkcBcRiSGFu4hIDCncRURi6P8BO1G5xTSGDukAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question: What is the accuracy you achieved on X_test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Fill - in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What modifications did you do to receive this score?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "Lab4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
