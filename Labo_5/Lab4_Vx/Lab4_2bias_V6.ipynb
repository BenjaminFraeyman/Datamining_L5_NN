{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Neural networks\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "> In this final exercise you will have to create a neural network to classify hand written numbers. Such a neural network is for example used in the post sorting process.\n",
    "\n",
    "> The dataset consists of images of hand written numbers ranging from 0 till 9.\n",
    "\n",
    "> Your goal is to train a neural network on the training set (*X_train*) and predict on the test_set (*X_test*)\n",
    "\n",
    "> Try to get an accuracy as high as possible. Decide yourself what to modify. You can modify for example: the learning_rate, amount of layers, neurons per layer, preprocessing methods, gradient descent to stochastic gradient descent/ batch gradient descent...\n",
    "\n",
    "> Feel free to change other aspects too if you want (e.g. activation function, but then you have to change to backprop algorithm).\n",
    "\n",
    "#### A few hints:\n",
    "\n",
    "> Calculate the accuracy on both the training set (X_train) and testing set (X_test) to see if there is a large difference\n",
    "\n",
    "> You can also do this every 5,10,... epochs (monitor the accuracy)\n",
    "\n",
    "> Calculate the loss on the training set, but also the test set (monitor the loss)\n",
    "\n",
    "> Plot these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Benjamin Fraeyman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from NN_Helper import Gradient_Checker\n",
    "gradient_checker = Gradient_Checker(limit=1.0*np.exp(-8))\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "from sklearn.datasets import load_digits\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create toy dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (1797L, 64L)\n",
      "y.shape: (1797L, 10L)\n",
      "X_train.shape: (1700L, 64L)\n",
      "X_test.shape: (97L, 64L)\n",
      "y_train.shape: (1700L, 10L)\n",
      "y_test.shape: (97L, 10L)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set containing samples with features\n",
    "data = load_digits(10)\n",
    "X = data['data']\n",
    "print \"X.shape:\", X.shape\n",
    "y = data['target']\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "y = encoder.fit_transform(np.reshape(y,(len(y),1))).toarray()\n",
    "print \"y.shape:\", y.shape\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_train = X[:1700]\n",
    "print \"X_train.shape:\", X_train.shape\n",
    "X_test = X[1700:]\n",
    "print \"X_test.shape:\", X_test.shape\n",
    "y_train = y[:1700]\n",
    "print \"y_train.shape:\", y_train.shape\n",
    "y_test = y[1700:]\n",
    "print \"y_test.shape:\", y_test.shape\n",
    "\n",
    "for i in range(1,10):\n",
    "    plt.subplot(3,3,i)\n",
    "    plt.imshow(np.reshape(X[i*100],(8,8)),cmap=plt.cm.gray,interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-use the code of exercise 3 (backwards, forwards, loss,...)** (you may use more cells if you want)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- reused code here --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples: 1700.0\n",
      "n_neurons: 10\n",
      "w1.shape: (64L, 10L)\n",
      "w2.shape: (10L, 10L)\n",
      "b1.shape: (1L, 10L)\n",
      "b2.shape: (1L, 10L)\n"
     ]
    }
   ],
   "source": [
    "n_samples = float(len(X_train))\n",
    "print \"n_samples:\", n_samples\n",
    "n_neurons = 10\n",
    "print \"n_neurons:\", n_neurons\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "w1 = 2*np.random.random((X_train.shape[1],n_neurons)) - 1\n",
    "print \"w1.shape:\", w1.shape\n",
    "w2 = 2*np.random.random((n_neurons,y_train.shape[1])) - 1\n",
    "print \"w2.shape:\", w2.shape\n",
    "\n",
    "# initialize the bias for every layer\n",
    "b1 = np.zeros((1,n_neurons))\n",
    "print \"b1.shape:\", b1.shape\n",
    "b2 = np.zeros((1,y_train.shape[1]))\n",
    "print \"b2.shape:\", b2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activiation function and the derivative of this function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "        output = 1/(1+np.exp(-x))\n",
    "        return output\n",
    "    \n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_output_to_derivative(output):\n",
    "        return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-use the forward propagation function you wrote in the previous exercise\n",
    "#update it to use a bias\n",
    "def forward(input_layer=None,weights=None,bias=None):\n",
    "    p = np.dot(input_layer,weights) +bias\n",
    "    a = sigmoid(p)\n",
    "    return a\n",
    "\n",
    "# https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/\n",
    "def backwards(input_layer=None,weights=None, a=None, dlda=None):\n",
    "    dadp = sigmoid_output_to_derivative(a)\n",
    "    \n",
    "    dpdw = input_layer.T\n",
    "    dldw = np.dot(dpdw,dlda*dadp)\n",
    "    \n",
    "    # (a+w) afgeleid naar w => 1\n",
    "    dldp = dlda*dadp\n",
    "    ones = np.ones((1, int(n_samples)))\n",
    "    dldb = np.dot(ones,dldp)\n",
    "    \n",
    "    dpdx = weights.T\n",
    "    dldx = np.dot(dlda*dadp, dpdx)\n",
    "    \n",
    "    dldw /= n_samples\n",
    "    dldb /= n_samples\n",
    "    return dldw,dldb,dldx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(predicted=None,target=None):\n",
    "    loss = 0.5*np.sum((predicted-target)**2)\n",
    "    loss /= n_samples\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Derivative of the loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss_derrivative(predicted=None,target=None):\n",
    "        dlda = predicted-target\n",
    "        return dlda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-- end of reused code --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 9999\n",
      "Good gradient, difference is: 0.00022617488004854404\n"
     ]
    }
   ],
   "source": [
    "#<Fill-in>-----------\n",
    "# A list to store the loss per epoch in. We can plot this later on to see if the network learns something\n",
    "loss_list=[]\n",
    "# How many times we will do the combination of forward and backward propagation\n",
    "n_epoch = 10000\n",
    "#learning rate\n",
    "learning_rate = 11\n",
    "# --------------------\n",
    "\n",
    "for iter in xrange(n_epoch):\n",
    "    a1 = forward(input_layer=X_train,weights=w1,bias=b1)\n",
    "    a2 = forward(input_layer=a1,weights=w2,bias=b2)\n",
    "    a3 = forward(input_layer=X_test,weights=w1,bias=b1)\n",
    "    a4 = forward(input_layer=a3,weights=w2,bias=b2)\n",
    "    loss = squared_loss(predicted=a2,target=y_train)\n",
    "    loss_list.append(loss)\n",
    "    dldw2, dldb2, dldx2 = backwards(input_layer= a1,weights=w2, a=a2, dlda = squared_loss_derrivative(predicted=a2,target=y_train))\n",
    "    dldw, dldb, dldx = backwards(input_layer= X_train,weights=w1, a=a1, dlda = dldx2/n_samples)\n",
    "#     if iter != 0.:\n",
    "#         if iter % 4999 == 0.:\n",
    "#             print \"iter:\", iter\n",
    "#             f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "#             gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    if iter == 9999:\n",
    "            print \"iter:\", iter\n",
    "            f = lambda x: squared_loss(target=y_train,predicted=forward(input_layer=forward(input_layer=X_train,weights=w1,bias=b1),weights=w2,bias=b2))\n",
    "            gradient_checker.gradient_check(X_train,y_train,dldx,f)\n",
    "    w1 += -learning_rate*dldw\n",
    "    w2 += -learning_rate*dldw2\n",
    "    b1 += -learning_rate*dldb\n",
    "    b2 += -learning_rate*dldb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305882352941176\n",
      "0.7835051546391752\n"
     ]
    }
   ],
   "source": [
    "#Calculate the accuracy for X_train using the \"accuracy_score\" function from scikit-learn which is already imported \n",
    "# (http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "print accuracy_score(np.argmax(y_train,axis=1), np.argmax(a2,axis=1))\n",
    "# #Calculate the accuracy for X_test using \"the accuracy_score\"\n",
    "print accuracy_score(np.argmax(y_test,axis=1), np.argmax(a4,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "\n",
      "The output of the network\n",
      "\n",
      "[[9.15268034e-06 4.47919340e-02 8.94305315e-01 ... 5.60769401e-09\n",
      "  9.23516737e-02 1.49532971e-04]\n",
      " [5.08327194e-06 1.71264905e-05 3.30936901e-01 ... 7.76312741e-07\n",
      "  4.48081470e-01 2.95340829e-02]\n",
      " [7.04405324e-09 6.00996659e-02 7.74639579e-01 ... 3.74691072e-07\n",
      "  2.22973588e-02 2.19100114e-05]\n",
      " ...\n",
      " [3.84724348e-12 8.24455191e-01 6.39597761e-02 ... 7.12978350e-03\n",
      "  5.15226010e-02 3.07567480e-05]\n",
      " [6.60599246e-06 1.93976043e-03 3.59829434e-04 ... 5.31800001e-04\n",
      "  6.28993910e-02 9.90831147e-01]\n",
      " [6.99501393e-09 5.86661188e-01 1.73705315e-01 ... 2.14410855e-06\n",
      "  1.16721397e-02 8.92908862e-07]]\n",
      "\n",
      "The ground truth:\n",
      "\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "Apply argmax on the output to get the index per row where the value is maximum\n",
      "\n",
      "Prediction network\n",
      "\n",
      "[2 8 2 ... 1 9 1]\n",
      "\n",
      "Ground truth\n",
      "\n",
      "[2 8 2 ... 1 9 1]\n"
     ]
    }
   ],
   "source": [
    "print \"Output After Training:\"\n",
    "print\n",
    "print \"The output of the network\"\n",
    "print\n",
    "print a2\n",
    "print\n",
    "print \"The ground truth:\"\n",
    "print\n",
    "print y_train\n",
    "print\n",
    "print\n",
    "print \"Apply argmax on the output to get the index per row where the value is maximum\"\n",
    "print\n",
    "print \"Prediction network\"\n",
    "print\n",
    "print np.argmax(a2,axis=1)\n",
    "print\n",
    "print \"Ground truth\"\n",
    "print\n",
    "print np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question: What is the accuracy you achieved on X_test?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Fill - in>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What modifications did you do to receive this score?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "Lab4.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
