{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Neural networks\n",
    "\n",
    "> This lab starts of with an example of a 1 layer neural network for classification purposes.\n",
    "\n",
    "> As a first exercise you will have to structure the neural network code better so it can be reused for a two-layer neural network\n",
    "\n",
    "> A second exercise consists of adding bias parameters to the layers.\n",
    "\n",
    "> A third exercise consists of running the network on new data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create toy dataset\n",
    "\n",
    "> The dataset (X) has the following dimensions: 6x4. This means 6 samples and 4 dimensions\n",
    "\n",
    "> The labels/ground truth (y) has the following dimensions 6x3. This means there are 6 samples and 3 classes. To encode the classes one-hot-encoding is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set containing samples with features\n",
    "X = np.array([  [0.,0.,1.,0.],\n",
    "                [0.,1.,1.,0.],\n",
    "                [1.,0.,1.,0.],\n",
    "                [1.,1.,1.,0.],\n",
    "                [0.,0.,1.,1.],\n",
    "                [0.,1.,1.,1.]])\n",
    "\n",
    "# Ground truth\n",
    "y = np.array([  [1.,0.,0.],\n",
    "                [1.,0.,0.],\n",
    "                [0.,1.,0.],\n",
    "                [0.,1.,0.],\n",
    "                [0.,0.,1.],\n",
    "                [0.,0.,1.]])\n",
    "\n",
    "n_samples = float(len(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weight matrix\n",
    "\n",
    "> The matrix has the following dimensions $[d,k]$\n",
    "\n",
    "> $d$ is the dimensionality of the data (4 in this case)\n",
    "\n",
    "> $k$ is the amount of classes (3 in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random numbers to make calculation\n",
    "# deterministic (just a good practice)\n",
    "np.random.seed(1)\n",
    "\n",
    "# initialize weights randomly with mean 0\n",
    "w = 2*np.random.random((4,3)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation function and the derivative of this function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(x):\n",
    "        output = 1/(1+np.exp(-x))\n",
    "        return output\n",
    "    \n",
    "# Derivative of the sigmoid function\n",
    "def sigmoid_output_to_derivative(output):\n",
    "        return output*(1-output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list to store the loss per epoch in. We can plot this later on to see if the network learns something\n",
    "loss_list=[]\n",
    "\n",
    "# How many times we will do the combination of forward and backward propagation\n",
    "n_epoch = 100000\n",
    "\n",
    "#learning rate\n",
    "learning_rate = 0.01\n",
    "\n",
    "for iter in range(n_epoch):\n",
    "\n",
    "    # Forwardpropagation\n",
    "    p = np.dot(X,w) # Dimensions X=[6x4], w=[4x3], so p=[6x4].[4x3]= 6x3\n",
    "    a = sigmoid(p) # Dimensions a=[6x3]\n",
    "\n",
    "    # Calculate the loss function\n",
    "    loss = 0.5*np.sum((a-y)**2) \n",
    "    \n",
    "    # Normalize loss (as it is calculated on all samples)\n",
    "    loss /= n_samples\n",
    "    \n",
    "    # Add the loss to the list of losses\n",
    "    loss_list.append(loss)\n",
    "    \n",
    "    # Backpropagation\n",
    "    # We need dLdw (the partial derivative of the loss with respect to the weights)\n",
    "    # We saw that using backpropagation (chain rule) that dLdw = dlda*dadp*dpdw\n",
    "    \n",
    "    dlda = a-y # Dimensions = [6x3]\n",
    "    dadp = sigmoid_output_to_derivative(a) # Dimensions = [6x3]\n",
    "    dpdw = X.T # Dimensions = [4x6]\n",
    "    \n",
    "    #dldw should be of the same dimensions as w itself.\n",
    "    #dlda is the partial derivative of the loss with respect to its input. This in fact says by how much we are making a wrong prediction\n",
    "    #dadp is the partial derivative of the activation with respect to the pre-activation. Hence we have to backpropagate dlda (the error), through the non-linearity\n",
    "    #dpdw is the partial derivative of the pre-activation with respect to the weights.\n",
    "    #dpdw indicates the rate of change of p with respect to w (how much p will change if we change w)\n",
    "    #This will in fact indicate how much each weight will have to be changed given the error\n",
    "    #dldw = [the rate of change of p with respect to w] dot [(the partial derivative of the loss with respect to its input)*(the partial derivate of the activation with respect to the preactivation)] \n",
    "    dldw = np.dot(dpdw,dlda*dadp) # Dimensions = [4x3] = [4x6].([6x3]*[6x3]) #To make sure the dimensions are ok, do dimensionality check.\n",
    "\n",
    "    # Normalize gradient (as it calculated on all samples)\n",
    "    dldw /= n_samples\n",
    "    \n",
    "    # update weights using the gradient descent update rule\n",
    "    w += -learning_rate*dldw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output After Training:\n",
      "()\n",
      "The output of the network\n",
      "()\n",
      "[[0.88975186 0.08097222 0.08335989]\n",
      " [0.90305226 0.06388478 0.06516458]\n",
      " [0.05945747 0.94688355 0.01616177]\n",
      " [0.06800183 0.93246856 0.01243509]\n",
      " [0.05946909 0.02025727 0.94667351]\n",
      " [0.068015   0.01576266 0.93154158]]\n",
      "()\n",
      "The ground truth:\n",
      "()\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "()\n",
      "()\n",
      "Apply argmax on the output to get the index per row where the value is maximum\n",
      "()\n",
      "Prediction network\n",
      "()\n",
      "[0 0 1 1 2 2]\n",
      "()\n",
      "Ground truth\n",
      "()\n",
      "[0 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"Output After Training:\")\n",
    "print()\n",
    "print(\"The output of the network\")\n",
    "print()\n",
    "print(a)\n",
    "print()\n",
    "print(\"The ground truth:\")\n",
    "print()\n",
    "print(y)\n",
    "print()\n",
    "print()\n",
    "print(\"Apply argmax on the output to get the index per row where the value is maximum\")\n",
    "print()\n",
    "print(\"Prediction network\")\n",
    "print()\n",
    "print(np.argmax(a,axis=1))\n",
    "print()\n",
    "print(\"Ground truth\")\n",
    "print()\n",
    "print(np.argmax(y,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#As we can see, the loss goes down. \n",
    "plt.plot(loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "name": "Short example.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
